# æ–°å¢ï¼šå¯¼å…¥æ—¥å¿—åº“ï¼ˆPythonè‡ªå¸¦ï¼Œä¸ç”¨é¢å¤–è£…ï¼‰
import logging
import time

# é…ç½®æ—¥å¿—ï¼šè®°å½•åˆ°æ–‡ä»¶+æ§åˆ¶å°éƒ½èƒ½çœ‹åˆ°
logging.basicConfig(
    level=logging.INFO,  # è®°å½•INFOåŠä»¥ä¸Šçº§åˆ«çš„æ—¥å¿—
    format="%(asctime)s - %(levelname)s - %(message)s",  # æ—¥å¿—æ ¼å¼ï¼šæ—¶é—´-çº§åˆ«-å†…å®¹
    handlers=[
        logging.FileHandler("data_tool.log", encoding="utf-8"),  # æ—¥å¿—ä¿å­˜åˆ°data_tool.logæ–‡ä»¶
        logging.StreamHandler()  # åŒæ—¶åœ¨ç»ˆç«¯æ˜¾ç¤ºæ—¥å¿—
    ]
)
logger = logging.getLogger(__name__)

# åŸæœ‰å¯¼å…¥ä»£ç ï¼ˆä¿®å¤HTTPExceptionå¯¼å…¥è·¯å¾„ï¼‰
import gradio as gr
import sqlite3
import csv
from fastapi import HTTPException  # é€‚é…æ–°ç‰ˆFastAPIçš„å¯¼å…¥è§„åˆ™

# å¤ç”¨ä¹‹å‰çš„æ•°æ®åº“è¿æ¥å‡½æ•°ï¼ˆä¸ç”¨æ”¹ï¼‰
def get_db_connection():
    conn = sqlite3.connect("algorithm_data.db")
    conn.row_factory = sqlite3.Row  # è®©æŸ¥è¯¢ç»“æœèƒ½æŒ‰åˆ—åè®¿é—®
    return conn

# 1. ä¸Šä¼ CSVåˆ°æ•°æ®åº“ï¼ˆæ•´åˆä¹‹å‰çš„ä¸Šä¼ é€»è¾‘+æŠ—é”™+æ—¥å¿—ï¼‰
def upload_csv_to_db(file):
    # æ–°å¢ï¼šè®°å½•æ“ä½œå¼€å§‹
    logger.info("å¼€å§‹æ‰§è¡Œã€ä¸Šä¼ CSVã€‘æ“ä½œ")
    if file is None:
        logger.warning("ä¸Šä¼ CSVå¤±è´¥ï¼šæœªé€‰æ‹©ä»»ä½•æ–‡ä»¶")  # æ–°å¢ï¼šè®°å½•è­¦å‘Šæ—¥å¿—
        return "âŒ è¯·å…ˆé€‰æ‹©è¦ä¸Šä¼ çš„CSVæ–‡ä»¶ï¼"
    try:
        # è¿æ¥æ•°æ®åº“ï¼Œåˆ›å»ºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS dataset (
                label TEXT,
                score REAL,
                feature1 REAL,
                feature2 REAL
            )
        """)
        # æ¸…ç©ºæ—§æ•°æ®ï¼ˆé¿å…é‡å¤ï¼‰
        cursor.execute("DELETE FROM dataset")
        
        # è¯»å–ä¸Šä¼ çš„CSVæ–‡ä»¶ï¼Œæ’å…¥æ•°æ®åº“
        with open(file.name, "r", encoding="utf-8") as f:
            csv_reader = csv.DictReader(f)
            for row in csv_reader:
                # æŠ—é”™ï¼šæ£€æŸ¥score/feature1/feature2æ˜¯å¦æ˜¯æ•°å­—
                try:
                    score = float(row["score"])
                    feature1 = float(row["feature1"])
                    feature2 = float(row["feature2"])
                except ValueError:
                    conn.close()
                    logger.error("ä¸Šä¼ CSVå¤±è´¥ï¼šæŸè¡Œçš„åˆ†æ•°/ç‰¹å¾ä¸æ˜¯æ•°å­—ï¼")
                    return f"âŒ CSVæ•°æ®é”™è¯¯ï¼šæŸè¡Œçš„åˆ†æ•°/ç‰¹å¾ä¸æ˜¯æ•°å­—ï¼"
                # æ’å…¥æ•°æ®
                cursor.execute("""
                    INSERT INTO dataset (label, score, feature1, feature2)
                    VALUES (?, ?, ?, ?)
                """, (row["label"], score, feature1, feature2))
        
        conn.commit()
        conn.close()
        logger.info("ä¸Šä¼ CSVæˆåŠŸï¼šæ–‡ä»¶=%s" % file.name)  # æ–°å¢ï¼šè®°å½•æˆåŠŸæ—¥å¿—
        return "âœ… CSVæ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼æ•°æ®åº“å·²æ›´æ–°ï½"
    except Exception as e:
        logger.error("ä¸Šä¼ CSVå¤±è´¥ï¼š%s" % str(e))  # æ–°å¢ï¼šè®°å½•é”™è¯¯æ—¥å¿—
        return f"âŒ ä¸Šä¼ å¤±è´¥ï¼š{str(e)}"

# 2. æŸ¥å•æ¡æ•°æ®ï¼ˆæ•´åˆä¹‹å‰çš„æŠ—é”™é€»è¾‘+æ—¥å¿—ï¼‰
def get_single_data_ui(data_id):
    logger.info("å¼€å§‹æ‰§è¡Œã€æŸ¥è¯¢å•æ¡æ•°æ®ã€‘æ“ä½œï¼Œè¾“å…¥ID=%s" % data_id)  # æ–°å¢
    try:
        data_id = int(data_id)
        if data_id <= 0:
            logger.warning("æŸ¥è¯¢å•æ¡æ•°æ®å¤±è´¥ï¼šID=%så¿…é¡»æ˜¯æ­£æ•°" % data_id)
            return "âŒ æ•°æ®IDå¿…é¡»æ˜¯æ­£æ•°å“¦ï¼ˆæ¯”å¦‚1ã€2ã€3ï¼‰ï¼", []
    except ValueError:
        logger.error("æŸ¥è¯¢å•æ¡æ•°æ®å¤±è´¥ï¼šID=%sä¸æ˜¯æ•°å­—" % data_id)
        return "âŒ IDå¿…é¡»æ˜¯æ•°å­—å“¦ï¼ˆæ¯”å¦‚1ã€2ã€3ï¼‰ï¼", []
    
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("""
        SELECT rowid, label, score, feature1, feature2 
        FROM dataset 
        WHERE rowid = ?
    """, (data_id,))
    row = cursor.fetchone()
    conn.close()
    
    if not row:
        logger.warning("æŸ¥è¯¢å•æ¡æ•°æ®å¤±è´¥ï¼šID=%sä¸å­˜åœ¨" % data_id)  # æ–°å¢
        return f"âŒ æ²¡æ‰¾åˆ°IDä¸º{data_id}çš„æ•°æ®å“¦ï¼", []
    # æ•´ç†æˆè¡¨æ ¼æ ¼å¼è¿”å›
    result = [["æ•°æ®ID", "æ ‡ç­¾", "å¾—åˆ†", "ç‰¹å¾1", "ç‰¹å¾2"],
              [row["rowid"], row["label"], row["score"], row["feature1"], row["feature2"]]]
    logger.info("æŸ¥è¯¢å•æ¡æ•°æ®æˆåŠŸï¼šID=%s" % data_id)  # æ–°å¢
    return "âœ… æŸ¥åˆ°æ•°æ®å•¦ï½", result

# 3. è¿‡æ»¤æ•°æ®ï¼ˆæ•´åˆä¹‹å‰çš„æŠ—é”™é€»è¾‘+æ—¥å¿—ï¼‰
def filter_data_ui(label, min_score):
    logger.info("å¼€å§‹æ‰§è¡Œã€è¿‡æ»¤æ•°æ®ã€‘æ“ä½œï¼Œæ ‡ç­¾=%sï¼Œæœ€ä½å¾—åˆ†=%s" % (label, min_score))  # æ–°å¢
    # æŠ—é”™ï¼šæ£€æŸ¥åˆ†æ•°èŒƒå›´
    if min_score < 0 or min_score > 1:
        logger.warning("è¿‡æ»¤æ•°æ®å¤±è´¥ï¼šæœ€ä½å¾—åˆ†=%sè¶…å‡º0-1èŒƒå›´" % min_score)
        return "âŒ æœ€ä½å¾—åˆ†å¿…é¡»åœ¨0åˆ°1ä¹‹é—´å“¦ï¼", []
    
    conn = get_db_connection()
    cursor = conn.cursor()
    if label.strip() != "":  # å¡«äº†æ ‡ç­¾å°±æŒ‰æ ‡ç­¾+åˆ†æ•°è¿‡æ»¤
        cursor.execute("""
            SELECT rowid, label, score, feature1, feature2 
            FROM dataset 
            WHERE label = ? AND score >= ?
        """, (label, min_score))
    else:  # æ²¡å¡«æ ‡ç­¾å°±åªæŒ‰åˆ†æ•°è¿‡æ»¤
        cursor.execute("""
            SELECT rowid, label, score, feature1, feature2 
            FROM dataset 
            WHERE score >= ?
        """, (min_score,))
    
    rows = cursor.fetchall()
    conn.close()
    
    if not rows:
        tip = f"âŒ æ²¡æ‰¾åˆ°æ ‡ç­¾ä¸º{label}ä¸”å¾—åˆ†â‰¥{min_score}çš„æ•°æ®å“¦ï¼" if label else f"âŒ æ²¡æ‰¾åˆ°å¾—åˆ†â‰¥{min_score}çš„æ•°æ®å“¦ï¼"
        logger.warning("è¿‡æ»¤æ•°æ®å¤±è´¥ï¼šæ ‡ç­¾=%sï¼Œæœ€ä½å¾—åˆ†=%s æ— åŒ¹é…æ•°æ®" % (label, min_score))  # æ–°å¢
        return tip, []
    
    # æ•´ç†æˆè¡¨æ ¼æ ¼å¼
    result = [["æ•°æ®ID", "æ ‡ç­¾", "å¾—åˆ†", "ç‰¹å¾1", "ç‰¹å¾2"]]
    for row in rows:
        result.append([row["rowid"], row["label"], row["score"], row["feature1"], row["feature2"]])
    logger.info("è¿‡æ»¤æ•°æ®æˆåŠŸï¼šæ‰¾åˆ°%sæ¡æ•°æ®" % (len(result)-1))  # æ–°å¢
    return f"âœ… æŸ¥åˆ°{len(result)-1}æ¡ç¬¦åˆæ¡ä»¶çš„æ•°æ®ï½", result

# 4. å¯¼å‡ºCSVï¼ˆæ•´åˆä¹‹å‰çš„æŠ—é”™é€»è¾‘+æ—¥å¿—ï¼‰
def export_csv_ui():
    logger.info("å¼€å§‹æ‰§è¡Œã€å¯¼å‡ºCSVã€‘æ“ä½œ")  # æ–°å¢
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT label, score, feature1, feature2 FROM dataset")
        rows = cursor.fetchall()
        conn.close()
        
        if not rows:
            logger.warning("å¯¼å‡ºCSVå¤±è´¥ï¼šæ•°æ®åº“ä¸ºç©º")  # æ–°å¢
            return "âŒ æ•°æ®åº“é‡Œè¿˜æ²¡æœ‰æ•°æ®å“¦ï¼å…ˆä¸Šä¼ CSVå†å¯¼å‡ºï½", None
        
        # è½¬æˆå­—å…¸æ ¼å¼ï¼Œå†™å…¥CSV
        rows_dict = []
        for row in rows:
            rows_dict.append({
                "label": row["label"],
                "score": row["score"],
                "feature1": row["feature1"],
                "feature2": row["feature2"]
            })
        
        csv_filename = "exported_dataset.csv"
        with open(csv_filename, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=["label","score","feature1","feature2"])
            writer.writeheader()
            writer.writerows(rows_dict)
        
        logger.info("å¯¼å‡ºCSVæˆåŠŸï¼šä¿å­˜ä¸ºexported_dataset.csv")  # æ–°å¢
        return "âœ… CSVå¯¼å‡ºæˆåŠŸï¼ç‚¹å‡»ä¸‹æ–¹æ–‡ä»¶ä¸‹è½½ï½", csv_filename
    except Exception as e:
        logger.error("å¯¼å‡ºCSVå¤±è´¥ï¼š%s" % str(e))  # æ–°å¢
        return f"âŒ å¯¼å‡ºå¤±è´¥ï¼š{str(e)}", None

# æ­å»ºGradioå¯è§†åŒ–ç•Œé¢ï¼ˆæ ¸å¿ƒï¼šæŠŠåŠŸèƒ½ç»„è£…æˆç½‘é¡µï¼‰
with gr.Blocks(title="æ•°æ®é›†ç®¡ç†å·¥å…·") as demo:
    gr.Markdown("# ğŸ“Š ç®—æ³•æ•°æ®é›†ç®¡ç†å·¥å…·")
    gr.Markdown("### ä¸ç”¨è®°æ¥å£ï¼Œç‚¹æŒ‰é’®å°±èƒ½æ“ä½œï½")
    
    # ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸Šä¼ CSV
    with gr.Tab("1. ä¸Šä¼ CSVåˆ°æ•°æ®åº“"):
        file_input = gr.File(label="é€‰æ‹©è¦ä¸Šä¼ çš„CSVæ–‡ä»¶ï¼ˆåˆ—ï¼šlabel,score,feature1,feature2ï¼‰", file_types=[".csv"])
        upload_btn = gr.Button("ğŸš€ ä¸Šä¼ å¹¶æ›´æ–°æ•°æ®åº“", variant="primary")
        upload_output = gr.Textbox(label="ä¸Šä¼ ç»“æœ")
        upload_btn.click(upload_csv_to_db, inputs=file_input, outputs=upload_output)
    
    # ç¬¬äºŒéƒ¨åˆ†ï¼šæŸ¥å•æ¡æ•°æ®
    with gr.Tab("2. æŸ¥å•æ¡æ•°æ®"):
        data_id_input = gr.Number(label="è¾“å…¥è¦æŸ¥è¯¢çš„æ•°æ®IDï¼ˆæ­£æ•°ï¼‰", value=1)
        query_btn = gr.Button("ğŸ” æŸ¥è¯¢æ•°æ®", variant="secondary")
        query_tip = gr.Textbox(label="æŸ¥è¯¢æç¤º")
        query_result = gr.Dataframe(label="æŸ¥è¯¢ç»“æœ", headers=["æ•°æ®ID", "æ ‡ç­¾", "å¾—åˆ†", "ç‰¹å¾1", "ç‰¹å¾2"])
        query_btn.click(get_single_data_ui, inputs=data_id_input, outputs=[query_tip, query_result])
    
    # ç¬¬ä¸‰éƒ¨åˆ†ï¼šè¿‡æ»¤æ•°æ®
    with gr.Tab("3. æŒ‰æ¡ä»¶è¿‡æ»¤æ•°æ®"):
        label_input = gr.Textbox(label="è¾“å…¥è¦è¿‡æ»¤çš„æ ‡ç­¾ï¼ˆç•™ç©ºåˆ™ä¸æŒ‰æ ‡ç­¾è¿‡æ»¤ï¼‰", placeholder="æ¯”å¦‚ï¼šcat")
        min_score_input = gr.Slider(label="æœ€ä½å¾—åˆ†ï¼ˆ0-1ï¼‰", minimum=0, maximum=1, value=0.8)
        filter_btn = gr.Button("ğŸ¯ è¿‡æ»¤æ•°æ®", variant="secondary")
        filter_tip = gr.Textbox(label="è¿‡æ»¤æç¤º")
        filter_result = gr.Dataframe(label="è¿‡æ»¤ç»“æœ", headers=["æ•°æ®ID", "æ ‡ç­¾", "å¾—åˆ†", "ç‰¹å¾1", "ç‰¹å¾2"])
        filter_btn.click(filter_data_ui, inputs=[label_input, min_score_input], outputs=[filter_tip, filter_result])
    
    # ç¬¬å››éƒ¨åˆ†ï¼šå¯¼å‡ºCSV
    with gr.Tab("4. å¯¼å‡ºCSVæ–‡ä»¶"):
        export_btn = gr.Button("ğŸ“¥ å¯¼å‡ºæ•°æ®åº“ä¸ºCSV", variant="primary")
        export_tip = gr.Textbox(label="å¯¼å‡ºæç¤º")
        export_file = gr.File(label="ä¸‹è½½å¯¼å‡ºçš„CSVæ–‡ä»¶")
        export_btn.click(export_csv_ui, inputs=[], outputs=[export_tip, export_file])

# å¯åŠ¨GradioæœåŠ¡ï¼ˆå›ºå®šä½ çš„WSL IPï¼Œä¸ç”¨æ”¹ï¼‰
if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",  # å…è®¸å¤–éƒ¨è®¿é—®
        server_port=7860,       # Gradioé»˜è®¤ç«¯å£
        share=False             # ä¸ç”¨å…¬å¼€é“¾æ¥ï¼Œåªç”¨æœ¬åœ°è®¿é—®
    )